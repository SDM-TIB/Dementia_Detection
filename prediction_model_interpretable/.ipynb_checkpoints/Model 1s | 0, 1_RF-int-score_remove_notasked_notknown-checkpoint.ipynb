{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from utils_int import *\n",
    "from defines_int import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, make_scorer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score, StratifiedShuffleSplit, StratifiedKFold\n",
    "import re\n",
    "\n",
    "import pathlib\n",
    "\n",
    "\n",
    "from sklearn.datasets import *\n",
    "from dtreeviz.trees import *\n",
    "from IPython.display import Image, display_svg, SVG\n",
    "\n",
    "\n",
    "# import lime\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "\n",
    "#pickle\n",
    "import pickle\n",
    "\n",
    "#import shap\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data from variable guide\n",
    "data_variable_cat = {}\n",
    "with open(\"data_variable_cat.pkl\", \"rb\") as f:\n",
    "    data_variable_cat = pickle.load(f)\n",
    "\n",
    "len(data_variable_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (orginal_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_pickle(orginal_data_path+'Optima_Data_Report_Cases_9584_filled_pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(attributes_considered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "attributes_considered += george_labels_one_years\n",
    "attributes_considered += george_labels_three_years\n",
    "attributes_considered = list(set(attributes_considered))\n",
    "len(attributes_considered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_dementia = [['CAMDEX ADMINISTRATION 1-12: EST SEVERITY OF DEMENTIA', [2, 3, 4]],\n",
    "           ['DIAGNOSIS 334-351: DEMENTIA   CLOUDED', [1]],\n",
    "           ['DIAGNOSIS 334-351: CLOUDED   DEMENTIA', [1]],\n",
    "           ['DIAGNOSIS 334-351: SEVERITY OF DEMENTIA', [1, 2, 3, 4]],\n",
    "           [\"OPTIMA DIAGNOSES V 2010: DEMENTIA PRESENT\", [1, 2, 3]],\n",
    "           [\"OPTIMA DIAGNOSES V 2010: MIXED DEMENTIA\", [1]],\n",
    "           [\"GENERAL INFORMATION: SPET SCORE\", [6]],\n",
    "           [\"GENERAL INFORMATION: DSM-IIIR\", [1]],\n",
    "           [\"GENERAL INFORMATION: CLINICAL DIAGNOSIS 1\", [1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "no_dementia = [['CAMDEX ADMINISTRATION 1-12: EST SEVERITY OF DEMENTIA', [0]],\n",
    "           ['DIAGNOSIS 334-351: SEVERITY OF DEMENTIA', [0]],\n",
    "           [\"OPTIMA DIAGNOSES V 2010: DEMENTIA PRESENT\", [0]],\n",
    "           [\"GENERAL INFORMATION: DSM-IIIR\", [0]],\n",
    "           [\"GENERAL INFORMATION: CLINICAL DIAGNOSIS 1\", [0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_dem = set()\n",
    "for i, j in all_dementia:\n",
    "    all_dem |= extract_values(data, i, j)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "no_dem = set()\n",
    "for i, j in no_dementia:\n",
    "    no_dem |= extract_values(data, i, j)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(no_dem), len(all_dem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "no_dem -= all_dem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(no_dem), len(all_dem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dem_patients = set(data.loc[all_dem].GLOBAL_PATIENT_DB_ID.unique())\n",
    "no_dem_patients = set(data.loc[no_dem].GLOBAL_PATIENT_DB_ID.unique())\n",
    "print(len(dem_patients), len(no_dem_patients))\n",
    "print(len(dem_patients.intersection(no_dem_patients)))\n",
    "no_dem_patients -= dem_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dem_patients), len(no_dem_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_no_dem = data.loc[no_dem]\n",
    "print(len(data_no_dem))\n",
    "data_no_dem = data_no_dem[data_no_dem['GLOBAL_PATIENT_DB_ID'].isin(no_dem_patients)]\n",
    "print(len(data_no_dem))\n",
    "data_no_dem['dementia_range'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_dem = data.loc[all_dem]\n",
    "data_dem['dementia_range'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_no_dem.shape, data_dem.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prepared_dataset = pd.concat([data_dem, data_no_dem])[attributes_considered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepared dataset without any modification\n",
    "prepared_dataset_org = prepared_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in zip(prepared_dataset, prepared_dataset.dtypes):\n",
    "    if not (j == \"float64\" or j == \"int64\"):\n",
    "        print(i)\n",
    "        prepared_dataset[i] = pd.to_numeric(prepared_dataset[i], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop irrelavent columns\n",
    "prepared_dataset = prepared_dataset.drop(columns=score_columns)\n",
    "prepared_dataset = prepared_dataset.replace([-1], [np.nan])\n",
    "prepared_dataset = drop_missing_columns(prepared_dataset, 0.70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currupt_categorical_columns = ['COGNITIVE EXAM 120-161: (158) REGISTERS OBJECTS', 'COGNITIVE EXAM 120-161: (137) IDENTIFIES OBJECTS',]\n",
    "confused_categorical_columns = ['COGNITIVE EXAM 162-187: (174) MIME - BRUSHING TEETH']                               \n",
    "categorical_columns = [col for col in prepared_dataset.columns if col in data_variable_cat.keys()]\n",
    "categorical_columns_final = list(set(categorical_columns)-set(currupt_categorical_columns)-set(confused_categorical_columns))\n",
    "drop_columns = ['DIAGNOSIS 334-351: DEPRESSIVE ILLNESS_0.0',\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in categorical_columns_final:\n",
    "    def replace_numerical_category(column, x):\n",
    "        if x in data_variable_cat[column]:\n",
    "            x = data_variable_cat[column][x]\n",
    "        else:\n",
    "            x = np.nan\n",
    "        return x\n",
    "    prepared_dataset[column]=prepared_dataset[column].apply(lambda x : replace_numerical_category(column, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_dataset[categorical_columns_final] = prepared_dataset[categorical_columns_final].replace([np.nan], ['Unknown'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace not asked and not known to 'Unknown'\n",
    "prepared_dataset[categorical_columns_final] = prepared_dataset[categorical_columns_final].replace(['Not asked'], ['Unknown'])\n",
    "prepared_dataset[categorical_columns_final] = prepared_dataset[categorical_columns_final].replace(['Not known'], ['Unknown'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mixed_type_list(l):\n",
    "    for i in range(0,len(l)-1):\n",
    "        if type(l[i])!=type(l[i+1]):\n",
    "            return True\n",
    "    return False\n",
    "        \n",
    "list_corrupted_columns = []        \n",
    "for col in categorical_columns:\n",
    "    if find_mixed_type_list(prepared_dataset[col].unique().tolist()):\n",
    "        list_corrupted_columns.append(col)\n",
    "        print (col,': ',prepared_dataset[col].unique().tolist())\n",
    "\n",
    "print(len(list_corrupted_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in list_corrupted_columns:\n",
    "    print (prepared_dataset.groupby(col)[col].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace notasked and doesnot know values\n",
    "# prepared_dataset[categorical_columns] = prepared_dataset[categorical_columns].replace([8, 9], [np.nan, np.nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_dataset[categorical_columns_final] = prepared_dataset[categorical_columns_final].replace(['Unknown'], [np.nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # drop rows with maximum number of missing values # drop missing values\n",
    "prepared_dataset = drop_missing_columns(prepared_dataset[prepared_dataset.isna().sum(axis=1)<15], 0.99)\n",
    "prepared_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if drop score columns\n",
    "# prepared_dataset = prepared_dataset[prepared_dataset['CAMDEX SCORES: MINI MENTAL SCORE']>=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prepared_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature transforamtion - one-hot encoding\n",
    "\n",
    "prepared_dataset_exp = prepared_dataset\n",
    "\n",
    "# select categorical data columns\n",
    "\n",
    "categorical_columns_final_exp = [col for col in prepared_dataset_exp.columns if col in categorical_columns_final]\n",
    "\n",
    "new_prepared_data = prepared_dataset_exp.drop(categorical_columns_final_exp, axis=1)\n",
    "for i in categorical_columns_final_exp:\n",
    "    x = pd.get_dummies(prepared_dataset_exp[i]).add_prefix(i+'::')\n",
    "    new_prepared_data = pd.concat([new_prepared_data, x], axis=1)\n",
    "    \n",
    "new_prepared_data['dementia_range'] = prepared_dataset_exp['dementia_range']\n",
    "\n",
    "prepared_dataset_exp = new_prepared_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_dataset_exp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepared_dataset_exp = prepared_dataset_exp.drop(columns=[col for col in prepared_dataset_exp.columns if '::Unknown' in col])\n",
    "# prepared_dataset_exp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop Nagative Features\n",
    "prepared_dataset_exp= prepared_dataset_exp.drop(columns=[col for col in prepared_dataset_exp.columns if '::Incorrect' in col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_dataset_exp = prepared_dataset_exp.dropna()\n",
    "prepared_dataset_exp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training\n",
    "def change_feature_names(feature_name):\n",
    "    p1 = '\\w.*\\d.*-\\d.*:\\s\\(\\d.*\\w\\)\\s'\n",
    "    p2 = '\\w.*:\\s'\n",
    "    feature_name = re.sub(p1, '', feature_name)\n",
    "    #feature_name = re.sub(p2, '', feature_name)\n",
    "    for key, value in score_dict.items():\n",
    "        if feature_name in key:\n",
    "            feature_name = feature_name+'{}'.format(value)\n",
    "    return feature_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([change_feature_names(fea) for fea in prepared_dataset_exp.columns.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "# X_full, y_full = prepared_dataset_exp.drop(columns=['dementia_range', 'COGNITIVE EXAM 162-187: (187) PATIENT', 'Age At Episode']), prepared_dataset_exp['dementia_range']\n",
    "X_full, y_full = prepared_dataset_exp.drop(columns=['dementia_range']), prepared_dataset_exp['dementia_range']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full.shape, y_full[y_full==0].shape, y_full[y_full==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# impute missing values\n",
    "\"\"\"knn_estimator = KNeighborsRegressor(n_neighbors=15)\n",
    "imputer = IterativeImputer(random_state=0, estimator=knn_estimator)\n",
    "X_full_imput = imputer.fit_transform(X_full)\n",
    "y_full_imput = y_full.values\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full_imput, y_full_imput = X_full.values, y_full.values\n",
    "\n",
    "# model training\n",
    "rf_estimator = RandomForestClassifier(max_depth=5, random_state=0)\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=123)\n",
    "important_features = set()\n",
    "important_features_size = 50\n",
    "for i, (train, test) in enumerate(cv.split(X_full_imput, y_full_imput)):\n",
    "    rf_estimator.fit(X_full_imput[train], y_full_imput[train])\n",
    "    y_predicted = rf_estimator.predict(X_full_imput[test])\n",
    "    print (classification_report(y_full_imput[test], y_predicted))\n",
    "    \n",
    "    # print important features\n",
    "    # model important feature\n",
    "    fea_importance = rf_estimator.feature_importances_\n",
    "    indices = np.argsort(fea_importance)[::-1]\n",
    "    for f in range(important_features_size):\n",
    "        # print(\"%d. feature: %s (%f)\" % (f + 1, X_full.columns.values[indices[f]], fea_importance[indices[f]]))\n",
    "        important_features.add(X_full.columns.values[indices[f]])\n",
    "    #lime interpretability \n",
    "    '''explainer = lime.lime_tabular.LimeTabularExplainer(np.array(X_full_imput[train]), \n",
    "                                                       feature_names=[change_feature_names(fea) for fea in X_full.columns.values], \n",
    "                                                       class_names= ['No Dementia', 'Dementia'],#rf_estimator.classes_, \n",
    "                                                       discretize_continuous=True, random_state=123)\n",
    "    exp = explainer.explain_instance(X_full_imput[test][5], rf_estimator.predict_proba, num_features=10)\n",
    "    #exp.show_in_notebook(show_table=True, show_all=False)\n",
    "    exp.save_to_file('model_1DT_'+str(i)+'.html')'''\n",
    "    #print (exp.as_list())\n",
    "    #fig = exp.as_pyplot_figure()\n",
    "    #plt.show()\n",
    "    \n",
    "    # shap interpretability\n",
    "    \n",
    "#important feature list\n",
    "print ('important_features: ', list(important_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prepared_dataset_exp_full = prepared_dataset_exp\n",
    "\n",
    "#Taking important features\n",
    "prepared_dataset_exp = prepared_dataset_exp[list(important_features)+['dementia_range']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(prepared_dataset_exp.drop(columns=['dementia_range']).values, prepared_dataset_exp['dementia_range'].values, test_size=0.3, random_state=42, stratify=prepared_dataset_exp['dementia_range'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Glance Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import graphviz\n",
    "from sklearn import tree\n",
    "from six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus, joblib\n",
    "from svglib.svglib import svg2rlg\n",
    "from reportlab.graphics import renderPDF, renderPM\n",
    "\n",
    "feature_names = prepared_dataset_exp.drop(columns=['dementia_range']).columns\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_depth=5, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "print (X_train.shape, y_train.shape)\n",
    "clf.score(X_test, y_test)\n",
    "y_pred = clf.predict(X_test)\n",
    "print (classification_report(y_test, y_pred))\n",
    "\n",
    "dot_data = StringIO()\n",
    "export_graphviz(clf, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True, feature_names=feature_names, \n",
    "               class_names=['No Dementia', 'Dementia'])\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_feature_names(feature_name):\n",
    "    p1 = '\\w.*\\d.*-\\d.*:\\s\\(\\d.*\\w\\)\\s'\n",
    "    p2 = '\\w.*:\\s'\n",
    "    feature_name = re.sub(p1, '', feature_name)\n",
    "    # feature_name = re.sub(p2, '', feature_name)\n",
    "    for key, value in score_dict.items():\n",
    "        if feature_name in key:\n",
    "            feature_name = feature_name+'{}'.format(value)\n",
    "    return feature_name\n",
    "    \n",
    "\n",
    "\n",
    "bool_feature_names_DT = prepared_dataset_exp.select_dtypes(include='uint8').columns\n",
    "feature_names_DT = [change_feature_names(i) for i in feature_names]\n",
    "bool_feature_names_DT = [change_feature_names(i) for i in  bool_feature_names_DT] # Important 0: NO and 1: YES\n",
    "bool_feature_names_true_DT = [i for i in bool_feature_names_DT if '::' in i] #('IDENTIFIES' in i or 'RECALL' in i) and '_1.0' in i ]\n",
    "bool_feature_names_false_DT = [i for i in bool_feature_names_DT if '::' in i] #('IDENTIFIES' in i or 'RECALL' in i) and '_0.0' in i ]\n",
    "feature_names_for_split_DT = [i for i in feature_names_DT if ' SCORE' in i] \n",
    "#print(feature_names_for_split_DT)\n",
    "\n",
    "\n",
    "viz = dtreeviz(clf, \n",
    "               x_data=X_train,\n",
    "               y_data=y_train,\n",
    "               target_name='class',\n",
    "               feature_names=feature_names_DT,\n",
    "               bool_feature_names_true=bool_feature_names_true_DT,\n",
    "               bool_feature_names_false=bool_feature_names_false_DT,\n",
    "               feature_names_for_split=feature_names_for_split_DT,\n",
    "               class_names=['No Dementia', 'Dementia'],\n",
    "               fancy=False, label_fontsize=40, ticks_fontsize=2)\n",
    "\n",
    "viz.save('model_1DT.svg')\n",
    "drawing = svg2rlg(\"./model_1DT.svg\".format(i))\n",
    "renderPDF.drawToFile(drawing, \"./model_1DT.pdf\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from svglib.svglib import svg2rlg\n",
    "drawing = svg2rlg(\"./method_1DT.svg\".format(i))\n",
    "renderPDF.drawToFile(drawing, \"./method_1DT.pdf\".format(i))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "1052+452"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
